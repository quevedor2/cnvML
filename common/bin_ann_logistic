##########################################
# Genomic Bin: MultiClass Classification #
##########################################
class MulticlassModels:
    def __init__(self, X=0, y=0, model=0, fine_tune_at=0, lr=0.00001):
        self.X = X
        self.y = y
        self.model=model
        self.fine_tune_at=fine_tune_at
        self.lr=lr
    
    def sr_model(self):
        print("Softmax-regression model")
        sr_model = Sequential()
        sr_model.add(Dense(y.shape[1], input_shape=(X.shape[1],), activation='softmax'))
        
        sr_model.compile(loss='categorical_crossentropy',
                         optimizer='adam',
                         metrics=['accuracy'])
        self.model=sr_model
    
    def ann_model(self):
        print("ANN model")
        #hidden_n=(X.shape[1] - y.shape[1])/40
        transfer_n=512
        hidden_n=(transfer_n * 1)
        deep_model = Sequential()
        deep_model.add(Dense(int(hidden_n), input_shape=(X.shape[1],), activation='relu'))
        deep_model.add(Dropout(rate=0.20))
        deep_model.add(Dense(transfer_n, activation='relu', name='transfer_1'))
        deep_model.add(Dense(y.shape[1], activation='softmax'))
        
        deep_model.compile(loss='categorical_crossentropy',
                           optimizer=Adam(learning_rate=self.lr),
                           metrics=['accuracy'])
        self.model=deep_model
    
    def transfer(self):
        print("Transfer learning at layer " + str(self.fine_tune_at))
        # Freeze all layers
        self.model.trainable = True
        
        # Make top layers trainable
        for layer in self.model.layers[:self.fine_tune_at]:
          layer.trainable =  False
        self.model.compile(optimizer=Adam(learning_rate=self.lr),
                           loss='categorical_crossentropy',
                           metrics=['accuracy'])


###########
# Modules #
###########
import pandas as pd
import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import sys
import seaborn as sns

from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold
from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

from pycnvML import load_data, model, anal, viz

######################################
# Data Visualization & Preprocessing #
######################################
CATEGORIES = ["ACC", "BLCA", "BRCA", "CESC", "CHOL", "COAD",
			  "DLBC", "ESCA", "GBM", "HNSC", "KICH", "KIRC",
			  "KIRP", "LAML", "LGG", "LIHC", "LUAD", "LUSC",
			  "MESO", "OV", "PAAD", "PCPG", "PRAD", "READ",
			  "SARC", "SKCM", "STAD", "TGCT", "THCA", "THYM",
			  "UCEC", "UCS", "UVM", "Normal"]

ref_analysis='TCGA_bin' #'TCGA_genes', 'TCGA_bin'
ccl_analysis='CCL_bin'
pdir='/cluster/projects/pughlab/projects/cancer_cell_lines/'
datadir=Path(os.path.join(pdir, ref_analysis))
os.chdir(datadir)
df = pd.read_csv(datadir / 'data' / 'Modal_Total_CN_matrix.csv')
df = df.drop([df.columns[0]], axis=1)
df = anal.balanceGrpDf(df, q=0.5)
model_type=sys.argv[1] # 'ann' or 'lr'

## Feature scaling and organizing X and y
X = df.values[:, :-1].astype("float")
X[np.isnan(X)] = 2
ss = StandardScaler() ## purpose: zero mean & unit STDERR
X = ss.fit_transform(X) ## Calculate parameters (mu, std) and transforms
# ss.transform() uses the learnt paramters only:
# stackexchange: difference-between-fit-and-fit-transform-in-scikit-learn-models

#ss = StandardScaler()
#X2 = ss.fit_transform(X)
y_class = [CATEGORIES.index(x) for x in df['cancer_type']]
y = tf.keras.utils.to_categorical(y_class, num_classes=len(CATEGORIES))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
    random_state=1234)

## setup and fit a multi-class logistic regression model
if not os.path.exists(os.path.join(datadir, 'models', model_type, 'model.h5')):
    M = MulticlassModels(X, y)
    if model_type == 'lr':
        M.sr_model()
    elif model_type == 'ann':
        M.ann_model()
    else:
        print("no model selected")
    
    hist = M.model.fit(X_train, y_train, epochs=25,  #epochs=25
        verbose=1, validation_split=0.2)
    M.model.save(os.path.join(datadir, 'models', model_type, 'model.h5'))
    M = M.model
else:
    print("Loading existing model...")
    M = load_model(os.path.join(datadir, 'models', model_type, 'model.h5'))

#y_pred_class = M.model.predict_classes(X_test, verbose=0)
#y_test_class = np.argmax(y_test, axis=1)
#print(classification_report(y_test_class, y_pred_class))
#plot_confusion_matrix(M.model, X_test, y_test_class)

###################
# Extract Weights #
###################
W = np.asmatrix(M.get_weights()[0])
np.savetxt(os.path.join(datadir, 'models', model_type, 'weights.csv'),
    W, fmt='%5.2f', delimiter=",")
    
W_ord = W.argsort(axis=0)
np.savetxt(os.path.join(datadir, 'models', model_type, 'weights_ord.csv'),
    W_ord.astype(int), fmt='%i', delimiter=",")

####################
# Spot-check model #
####################
## Test performance
print("Plotting confusion matrix...")
cm = viz.plot_confusion_matrix(M, X_test, np.argmax(y_test, axis=1), range(0, len(CATEGORIES)),
                           os.path.join(datadir, "models",
                           model_type, "lr_confusion-matrix.png"))
plt.close("all")

f1 = viz.plot_class_cm(cm, os.path.join(datadir, "models",
                   model_type, "cnn_cm_barplot.png"))
np.savetxt(os.path.join(datadir, 'models', model_type, 'F1_test.csv'),
    f1, fmt='%5.2f', delimiter=",", header='ID,Frac,Cnt,Total')
plt.close("all")
np.nanmean(f1.Frac) ## ann: 0.7931034482758621 lr: 0.6893085349795387


############################
# Transfer learning to CCL #
############################
## Read in CCL data
CCLDIR=Path(os.path.join(pdir, ccl_analysis))
CCL_DATADIR=os.path.join(CCLDIR, "data")
CCL_OUTDIR=os.path.join(CCLDIR, "models")

dataset = 'GDSC'
ccl_df = pd.read_csv(os.path.join(CCL_DATADIR, dataset, 'Modal_Total_CN_matrix.csv'))
ccl_df = ccl_df.drop([ccl_df.columns[0]], axis=1)

## Feature scaling and organizing X and y
ccl_X = ccl_df.values[:, :-1].astype("float")
ccl_X[np.isnan(ccl_X)] = 2

## Map only cell line Oncocodes that overlap with TCGA
ccl_tcga_ov = ccl_df['cancer_type'].isin(CATEGORIES)
ccl_tcga_ov.value_counts() #False    410; True     558

ccl_XT = ccl_X[ccl_tcga_ov,:]
ccl_XT = ss.transform(ccl_XT) ## Calculate parameters (mu, std) and transforms
ccl_yT = ccl_df['cancer_type'][ccl_tcga_ov]
ccl_yT_class = [ CATEGORIES.index(x) for x in ccl_yT ]
y_ccl_one_hot = tf.keras.utils.to_categorical(ccl_yT_class,
    num_classes=len(CATEGORIES))
y_ccl_one_hot_naive = pd.get_dummies(ccl_yT).values

Mtransfer = MulticlassModels(model=M, fine_tune_at=2, lr=0.0001)
Mtransfer.transfer()
hist_Tccl = Mtransfer.model.fit(ccl_XT, y_ccl_one_hot, batch_size=32, epochs=20, validation_split=0.2)
Mtransfer.model.save(os.path.join(datadir, 'models', model_type, 'my_tcga_model_layer2-transfer.h5'))

Mnaive=MulticlassModels(ccl_XT, y_ccl_one_hot, lr=0.0001)
Mnaive.ann_model()
hist_Nccl = Mnaive.model.fit(ccl_XT, y_ccl_one_hot, batch_size=32, epochs=20, validation_split=0.2)
Mnaive.model.save(os.path.join(datadir, 'models', model_type, 'my_tcga_model_layer2-naive.h5'))

for tl in ['naive', 'raw', 'transfer']:
    if tl == 'transfer':
        M = load_model(os.path.join(datadir, 'models', model_type, 'my_tcga_model_layer2-transfer.h5'))
    elif tl == 'raw':
        M = load_model(os.path.join(datadir, 'models', model_type, 'model.h5'))
    else:
        M = load_model(os.path.join(datadir, 'models', model_type, 'my_tcga_model_layer2-naive.h5'))
    
    CAT = CATEGORIES
    
    for dataset in ['CCLE', 'GNE', 'GDSC']:
        ccl_df = pd.read_csv(os.path.join(CCL_DATADIR, dataset, 'Modal_Total_CN_matrix.csv'))
        ccl_df = ccl_df.drop([ccl_df.columns[0]], axis=1)
        
        ## Feature scaling and organizing X and y
        ccl_X = ccl_df.values[:, :-1].astype("float")
        ccl_X[np.isnan(ccl_X)] = 2
        
        ## Map only cell line Oncocodes that overlap with TCGA
        ccl_tcga_ov = ccl_df['cancer_type'].isin(CAT)
        ccl_tcga_ov.value_counts() #False    410; True     558
        
        ccl_XT = ccl_X[ccl_tcga_ov,:]
        ccl_XT = ss.transform(ccl_XT) ## Calculate parameters (mu, std) and transforms
        ccl_yT = ccl_df['cancer_type'][ccl_tcga_ov]
        ccl_yT_class = [ CAT.index(x) for x in ccl_yT ]
        ccl_yT_pred = M.predict_classes(ccl_XT, verbose=0)
        
        ## Test performance on CCL
        print("Plotting confusion matrix...")
        print(tl + " min: " + str(np.min(ccl_yT_class)))
        if(not os.path.isdir(os.path.join(CCLDIR, "models", model_type, dataset))):
             os.makedirs(os.path.join(CCLDIR, "models", model_type, dataset))
        ccl_cm = viz.plot_confusion_matrix(M, ccl_XT, ccl_yT_class,
                                    range(0, len(CAT)), # use to be 0,
                                    os.path.join(CCLDIR, "models",
                                    model_type, dataset, tl  + "_CCLlr_confusion-matrix.png"))
        plt.close("all")
        
        f1 = viz.plot_class_cm(ccl_cm, os.path.join(CCLDIR, "models", model_type,
            dataset, tl  + "_CCL_cm_barplot.png"))
        plt.close("all")
        np.savetxt(os.path.join(CCLDIR, 'models', model_type, dataset, tl  + '_F1_test.csv'),
            f1, fmt='%5.2f', delimiter=",", header='ID,Frac,Cnt,Total')
