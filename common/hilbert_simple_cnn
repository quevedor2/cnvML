#################
# Preprocessing #
#################
def balanceGrp(X, y, q=0.5):
    cnts = np.unique(y, return_counts=True)
    target_n = int(np.quantile(cnts[1], q))
    min_n = int(target_n/4)
    frames = np.zeros((len(cnts[0])*target_n, 1))
    for ctype in cnts[0]:
        fill_idx = int(np.argwhere(ctype==cnts[0])) * target_n
        ctype_idx = np.argwhere(y==ctype)
        np.random.seed(seed=1234)
        
        if ctype_idx.shape[0] < min_n:
            print(str(ctype) + " [Remove]: " + str(ctype_idx.shape[0])
                + " < " + str(min_n))
            sample_idx = np.zeros(target_n) - 1
        elif ctype_idx.shape[0] < target_n:
            print(str(ctype) + " [Upsample]: " + str(ctype_idx.shape[0])
                + " < " + str(target_n))
            sample_idx = np.random.choice(ctype_idx[:,0],
                                          size=target_n, replace=True)
        elif ctype_idx.shape[0] > target_n:
            print(str(ctype) + " [Downsample]: " + str(ctype_idx.shape[0])
                + " > " + str(target_n))
            sample_idx = np.random.choice(a=ctype_idx[:,0], size=target_n,
                                          replace=False)
        else:
            sample_idx = ctype_idx[:,0]
        frames[fill_idx:fill_idx+target_n,0] = sample_idx
    
    
    frames = frames[frames[:,0] >= 0,:]
    X_bal=X[frames[:,0].astype('int'),:,:,:]
    y_bal=y[frames[:,0].astype('int'),:]
    return X_bal,y_bal

##############
# CNN Models #
##############
class CNN:
    def __init__(self, y=0, width=300, height=300, channel=3, model=0, fine_tune_at=0):
        self.y=y
        self.width=width
        self.height=height
        self.channel=channel
        self.model=model
        self.img_size=[width, height, channel]
        self.fine_tune_at=fine_tune_at
    
    def model_one(self):
        print("CNN model 1")
        model = Sequential()
        model.add(Conv2D(filters=32,  kernel_size=(3,3), activation='relu',
                         padding='same', input_shape=self.img_size))
        model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(rate=0.25))
        
        model.add(Conv2D(filters=64,  kernel_size=(3,3), activation='relu', padding='same'))
        model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(rate=0.25))
        model.add(Flatten())
        
        model.add(Dense(units=512, activation='relu'))
        model.add(Dropout(rate=0.20))
        model.add(Dense(units=self.y.max()+1, activation='softmax'))
        
        model.compile(loss='categorical_crossentropy',
                      optimizer='adam',
                      metrics=['accuracy'])
        self.model=model
    
    def model_two(self):
        print("CNN model 2")
        model = Sequential()
        model.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_1',
                         input_shape=self.img_size))
        model.add(MaxPooling2D((2, 2), name='maxpool_1'))
        model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='conv_2'))
        model.add(MaxPooling2D((2, 2), name='maxpool_2'))
        model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_3'))
        model.add(MaxPooling2D((2, 2), name='maxpool_3'))
        model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='conv_4'))
        model.add(MaxPooling2D((2, 2), name='maxpool_4'))
        model.add(Flatten())
        model.add(Dropout(rate=0.25))
        
        model.add(Dense(512, activation='relu', name='dense_1'))
        #model.add(Dropout(rate=0.20))
        model.add(Dense(units=self.y.max()+1, activation='softmax'))
        
        model.compile(optimizer='adam',
                      loss='categorical_crossentropy',
                      metrics=['accuracy'])
        self.model=model
    
    def transfer(self):
        print("Transfer learning at layer " + str(self.fine_tune_at))
        # Freeze all layers
        self.model.trainable = True
        
        # Make top layers trainable
        for layer in self.model.layers[:self.fine_tune_at]:
          layer.trainable =  False
        self.model.compile(optimizer='adam',
                           loss='categorical_crossentropy',
                           metrics=['accuracy'])


#################
# Visualization #
#################
def plotX(X, outfile):
    plt.imshow(X.reshape(IMG_SIZE, IMG_SIZE,3))
    plt.savefig(outfile)
    plt.close("all")

def plot_loss_accuracy(hist, outfile):
    acc = hist.history['accuracy']
    val_acc = hist.history['val_accuracy']
    loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    
    fig, (ax1, ax2) = plt.subplots(2, sharex=True)
    ax1.plot(acc, label='Training Accuracy')
    ax1.plot(val_acc, label='Validation Accuracy')
    ax1.legend(loc='lower right')
    ax1.set_ylabel('Accuracy')
    ax1.set_ylim(0, 1.0) #([min(plt.ylim()),1])
    
    ax2.plot(loss, label='Training Loss')
    ax2.plot(val_loss, label='Validation Loss')
    ax2.legend(loc='upper right')
    ax2.set_ylabel('Cross Entropy')
    ax2.set_xlabel('epoch')
    fig.show()
    fig.savefig(outfile)

def plot_confusion_matrix(model, X, y, range_y, outfile):
    y_pred = list(model.predict_classes(X, verbose=0))
    y = list(y)
    plt.figure(figsize=(8, 6))
    
    # Ensure that all the classes are represented
    y.extend(list(range_y))
    y_pred.extend(list(range_y))
    cm=confusion_matrix(y, y_pred)
    np.fill_diagonal(cm, list(cm.diagonal()-1))
    
    # Make the heatmaps!!!
    sns.heatmap(pd.DataFrame(cm), annot=True, fmt='d', cmap='YlGnBu', alpha=0.8, vmin=0)
    plt.savefig(outfile)
    return cm

def plot_class_cm(cm, outfile,metric ='f1'):
    (p, r, f1) = get_F1score(cm)
    if (metric is 'f1'):
        class_frac=f1
    elif (metric is 'p'):
        class_frac = p
    else:
        class_frac = r
    
    class_frac=class_frac.round(2)
    class_id=list(range(0, len(class_frac)))
    class_df = pd.DataFrame({'ID':class_id, 'Frac':class_frac,
                            'Cnt':cm.diagonal(), 'Total':cm.sum(0)})
    
    #b1=plt.bar("ID", "Total", data=class_df,class_id, class_frac)
    b2=plt.bar("ID", "Frac", data=class_df)
    plt.ylim((0,1))
    #plt.rcParams["figure.figsize"] = [6,2]
    plt.xlabel("Cancer_Types")
    plt.ylabel(metric)
    plt.subplots_adjust(bottom=0.2, top=0.8)
    plt.xticks(class_id, rotation=90)
    plt.savefig(outfile)
    
    return class_df

def get_F1score(cm):
    precision = cm.diagonal() / cm.sum(axis=0)
    recall = cm.diagonal() / cm.sum(axis=1)
    f1 = 2 * ((precision * recall)/(precision + recall))
    return (precision, recall, f1)

######################
# Feature Extraction #
######################
def create_occlusion_dataset(occ, IMG_SIZE=300, step=10):
    occ_idx=list(range(0, IMG_SIZE, step))
    # Initialize zeroes np.array
    occ_arr=np.zeros((len(occ_idx)*len(occ_idx),
                      IMG_SIZE, IMG_SIZE, 3))
    arr_ind=0
    for ypos in occ_idx:
        for xpos in occ_idx:
            occ_tmp=occ.copy()
            # Blank out box area
            occ_tmp[xpos:(xpos+step-1), ypos:(ypos+step-1),] = 1
            occ_arr[arr_ind,:,:,:] = occ_tmp
            arr_ind=arr_ind+1
    
    return occ_arr

def fill_occ_array(p, IMG_SIZE=300, step=50):
    occ_idx=list(range(0, IMG_SIZE, step))
    
    # Initialize zeroes np.array
    occ_viz=np.zeros((IMG_SIZE, IMG_SIZE,3))
    arr_ind=0
    for ypos in occ_idx:
        for xpos in occ_idx:
            yidx=ypos if ypos == 0 else ypos - 1
            xidx=xpos if xpos == 0 else xpos - 1
            occ_viz[xidx:(xpos+step-1), yidx:(ypos+step-1),] = p[arr_ind]
            arr_ind=arr_ind+1
    return occ_viz

#############
# Load Data #
#############
import imutils
import cv2
import pandas as pd
import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import pickle
import sys
import seaborn as sns
from itertools import compress

from sklearn.metrics import confusion_matrix, classification_report, r2_score
from sklearn.model_selection import train_test_split

import tensorflow.keras
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D

os.chdir("/cluster/home/quever/git/cnvML")
from pyimagesearch.gradcam import GradCAM
from occlusioncnn.occlusion import Occlusion

# VARIABLES
PDIR='/cluster/projects/pughlab/projects/cancer_cell_lines'
DATADIR = os.path.join(PDIR, "TCGA", "data")
OUTDIR = os.path.join(PDIR, "TCGA", "models")
IMG_SIZE=300
model_type=sys.argv[1]
CATEGORIES = ["ACC", "BLCA", "BRCA", "CESC", "CHOL", "COAD",
              "DLBC", "ESCA", "GBM", "HNSC", "KICH", "KIRC",
              "KIRP", "LAML", "LGG", "LIHC", "LUAD", "LUSC",
              "MESO", "OV", "PAAD", "PCPG", "PRAD", "READ",
              "SARC", "SKCM", "STAD", "TGCT", "THCA", "THYM",
              "UCEC", "UCS", "UVM", "Normal"]
              
# Load data from TCGA Hilberts
pickle_X = open(os.path.join(DATADIR, "X.pickle"), "rb")
pickle_y = open(os.path.join(DATADIR, "y.pickle"), "rb")
X = pickle.load(pickle_X)
y = pickle.load(pickle_y)
X,y = balanceGrp(X, y, q=0.5)
#plt.imshow(X[2,].reshape(IMG_SIZE, IMG_SIZE,3))
#plt.savefig(os.path.join(OUTDIR, model_type, "class_25.png"))
#plt.close("all")

#X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)

x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=1234)

## Occlusion visualization check
#i=0
#occ_array = create_occlusion_dataset(x_train[i].copy(), 300, 10)
#plt.imshow(occ_array[200,].reshape(IMG_SIZE, IMG_SIZE,3))
#plt.savefig(os.path.join(OUTDIR, model_type, "occlusion_test.png"))
#plt.close("all")


# One-hot encoding of y
y_train_one_hot = tensorflow.keras.utils.to_categorical(y_train,
    num_classes=len(CATEGORIES))
y_test_one_hot = tensorflow.keras.utils.to_categorical(y_test,
    num_classes=len(CATEGORIES))

# Format
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train = x_train / 255
x_test = x_test / 255

########################
# Build/Train ConvNet #
########################
if not os.path.exists(os.path.join(OUTDIR, model_type, 'my_tcga_model_layer2.h5')):
    M=CNN(y, width=IMG_SIZE, height=IMG_SIZE, channel=3)
    if model_type=='model1':
        M.model_one()
    elif model_type=='model2':
        M.model_two()
    else:
        print("no model selected")
        
    hist = M.model.fit(x_train, y_train_one_hot, batch_size=32, epochs=10, validation_split=0.2)
    M.model.evaluate(x_test, y_test_one_hot)[1]
    M.model.save(os.path.join(OUTDIR, model_type, 'my_tcga_model_layer2.h5'))
    plot_loss_accuracy(hist, os.path.join(OUTDIR, model_type, "cnn_performance.png"))
    M=M.model
else:
    print("Loading existing model...")
    M = load_model(os.path.join(OUTDIR, model_type, 'my_tcga_model_layer2.h5'))

####################
# Spot-check model #
####################
y_test_class = np.argmax(y_test_one_hot, axis=1)
cm = plot_confusion_matrix(M, x_test, y_test_class, range(0, len(CATEGORIES)),
                           os.path.join(OUTDIR, model_type, "cnn_confusion-matrix.png"))
plt.close("all")

f1 = plot_class_cm(cm, os.path.join(OUTDIR, model_type, "cnn_cm_barplot.png"))
plt.close("all")
np.savetxt(os.path.join(OUTDIR, model_type, 'F1_test.csv'),
    f1, fmt='%5.2f', delimiter=",", header='ID,Frac,Cnt,Total')
np.nanmean(f1.Frac) #model2: 0.749264630372789

################################
# Average Class-Activation Map #
################################
os.makedirs(os.path.join(PDIR, "TCGA", "ctype_avgs"))
for ctype in list(range(y.min(), y.max()+1)):
    print(CATEGORIES[ctype] + "-" + str(ctype))
    ## Create an average representation of the cancer type
    ov_idx = y == ctype
    ctype_X = X[ov_idx[:,0],:]
    ctype_X = ctype_X.mean(axis=0).astype("int")
    
    ## Plot the CN plot for an average cancer-type
    plotX(ctype_X, os.path.join(PDIR, "TCGA", "ctype_avgs",
        str(ctype) + "_" + CATEGORIES[ctype]))
    
    ## Plot the Class-activation map for an average cancer-type
    ctype_X = ctype_X.astype("uint8")
    image = np.expand_dims(ctype_X, axis=0)
    image = image.astype('float32')
    image = image / 255
    
    cam = GradCAM(M, ctype)
    cams, heatmap = cam.compute_heatmap_raw(image)
    heatmap = cam.compute_heatmap(image)
    heatmap = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE))
    (heatmap, output) = cam.overlay_heatmap(heatmap, ctype_X, alpha=0.5)
    output = np.vstack([ctype_X, heatmap, output])
    output = imutils.resize(output, height=700)
    cv2.imwrite(os.path.join(PDIR, "TCGA", "ctype_avgs",
        "CAM_" + str(ctype) + "-" + CATEGORIES[ctype] + ".jpg"), output)
    
    ## Plot occlusion map
    occ = Occlusion(model=M, img=image[0,:].copy(), IMG_SIZE=IMG_SIZE)
    occ.create_occlusion_dataset(step=10, mem='high')
    occ.predict_occlusion()
    occ.fill_occ_array(ctype=ctype)
    heatmap_occ = 255 - occ.winsorize_heatmap()
    heatmap_occ = occ.quantile_match(heatmap_occ, heatmap)
    (heatmap_occ, output_occ) = occ.overlay_heatmap(heatmap_occ, ctype_X, colormap=cv2.COLORMAP_INFERNO)
    
    output_occ = np.vstack([ctype_X, heatmap_occ, output_occ])
    output_occ = imutils.resize(output_occ, height=700)
    cv2.imwrite(os.path.join(PDIR, "TCGA", "ctype_avgs",
        "OCC_" + str(ctype) + "-" + CATEGORIES[ctype] + ".jpg"), output_occ)



#################
# Occlusion Map #
#################
cl=3
cl_samples = [i for i, x in enumerate(y_train==cl) if x]
gt_prob=M.predict_proba(x_train[cl_samples,:], verbose=False)[0,y_train[i]].round(3)
x2= x_train.mean(axis=0)
plt.imshow(x2.reshape(IMG_SIZE, IMG_SIZE,3))
plt.savefig(os.path.join(OUTDIR, model_type, "occlusion_test.png"))
plt.close("all")

ctype_avg=np.zeros((len(cl_samples), IMG_SIZE, IMG_SIZE, 3))
arr_ind=0
for i in cl_samples[0:50]:
    print(arr_ind)
    occ_array = create_occlusion_dataset(x_train[i].copy(), 300, 10)
    occ_prob=M.predict_proba(occ_array, verbose=False)[:,y_train[i]].round(3)
    occ_viz=fill_occ_array(occ_prob, IMG_SIZE,10)
    ctype_avg[arr_ind,:,:,:] = (occ_viz - np.median(occ_viz))
    arr_ind=arr_ind+1

x3 = ctype_avg[0:50].mean(axis=0)

plt.imshow(x3.reshape(IMG_SIZE, IMG_SIZE,3)[:,:,0], cmap='inferno',
           vmin=np.quantile(x3, 0.05), vmax=np.quantile(x3, 0.95))
plt.savefig(os.path.join(OUTDIR, model_type, "occlusion_p.png"))
plt.close("all")

plt.contour(x3.reshape(IMG_SIZE, IMG_SIZE,3)[:,:,0],
            levels=np.logspace(np.quantile(x3, 0.05), np.quantile(x3, 0.25), np.quantile(x3, 0.5)),
            colors='black', alpha=1)
plt.savefig(os.path.join(OUTDIR, model_type, "occlusion_p2.png"))
plt.close("all")


############################
# Transfer learning to CCL #
############################
CCLDIR=Path(os.path.join(PDIR, 'CCL'))
CCL_DATADIR=os.path.join(CCLDIR, "data")
CCL_OUTDIR=os.path.join(CCLDIR, "models")
dataset = 'GDSC'
ccl_pickle_X = open(os.path.join(CCL_DATADIR, dataset, "X.pickle"), "rb")
ccl_pickle_y = open(os.path.join(CCL_DATADIR, dataset, "y.pickle"), "rb")
ccl_X = pickle.load(ccl_pickle_X)
ccl_y = pickle.load(ccl_pickle_y)

ccl_CAT=[]
for o in os.listdir(os.path.join(CCL_DATADIR, dataset)):
    if os.path.isdir(os.path.join(CCL_DATADIR, dataset, o)):
        ccl_CAT.append(o)

ccl_y_verbose = [ccl_CAT[int(i)] for i in ccl_y]
ccl_tcga_ov = [elem in CATEGORIES for elem in ccl_y_verbose]

# Format
ccl_XT = ccl_X[ccl_tcga_ov,:]
ccl_XT = ccl_XT.astype('float32')
ccl_XT = ccl_XT / 255

ccl_yT = list(compress(ccl_y_verbose, ccl_tcga_ov))
ccl_yT_class = [ CATEGORIES.index(x) for x in ccl_yT ]
#ccl_XT,ccl_yT_class = balanceGrp(ccl_XT, np.c_[ccl_yT_class], q=0.5)
y_ccl_one_hot = tensorflow.keras.utils.to_categorical(ccl_yT_class,
    num_classes=len(CATEGORIES))


## Make new models
Mtransfer = CNN(model=M, fine_tune_at=2)
Mtransfer.transfer()
hist_Tccl = Mtransfer.model.fit(ccl_XT, y_ccl_one_hot, batch_size=32, epochs=10, validation_split=0.2)

Mnaive=CNN(y, width=IMG_SIZE, height=IMG_SIZE, channel=3)
Mnaive.model_two()
hist_Nccl = Mnaive.model.fit(ccl_XT, y_ccl_one_hot, batch_size=32, epochs=10, validation_split=0.2)

for tl in ['transfer', 'naive', 'raw']:
    if tl == 'transfer':
        M = Mtransfer.model
        CAT = CATEGORIES
    elif tl == 'raw':
        M = load_model(os.path.join(OUTDIR, model_type, 'my_tcga_model_layer2.h5'))
        CAT = CATEGORIES
    else:
        M = Mnaive.model
        CAT = CATEGORIES
    
    for dataset in ['CCLE', 'GNE', 'GDSC']:
        ccl_pickle_X = open(os.path.join(CCL_DATADIR, dataset, "X.pickle"), "rb")
        ccl_pickle_y = open(os.path.join(CCL_DATADIR, dataset, "y.pickle"), "rb")
        ccl_X = pickle.load(ccl_pickle_X)
        ccl_y = pickle.load(ccl_pickle_y)
        
        ccl_CAT=[]
        for o in os.listdir(os.path.join(CCL_DATADIR, dataset)):
            if os.path.isdir(os.path.join(CCL_DATADIR, dataset, o)):
                ccl_CAT.append(o)
        
        ccl_y_verbose = [ccl_CAT[int(i)] for i in ccl_y]
        ccl_tcga_ov = [elem in CATEGORIES for elem in ccl_y_verbose]
        np.unique(ccl_tcga_ov, return_counts=True) # (array([False,  True]), array([544, 401]))
        
        # Format
        ccl_X = ccl_X.astype('float32')
        ccl_X = ccl_X / 255
        
        ccl_XT = ccl_X[ccl_tcga_ov,:]
        ccl_yT = list(compress(ccl_y_verbose, ccl_tcga_ov))
        
        ## Do prediction testing
        ccl_yT_class = [ CATEGORIES.index(x) for x in ccl_yT ]
        ccl_yT_pred = M.predict_classes(ccl_XT, verbose=0)
        
        ## Test performance on CCL
        print("Plotting confusion matrix...")
        if(not os.path.isdir(os.path.join(CCLDIR, "models", model_type, dataset))):
             os.makedirs(os.path.join(CCLDIR, "models", model_type, dataset))
        ccl_cm = plot_confusion_matrix(M, ccl_XT, ccl_yT_class, range(0, len(CATEGORIES)),
                                    os.path.join(CCLDIR, "models",
                                    model_type, dataset, tl  + "_CCLlr_confusion-matrix.png"))
        plt.close("all")
        
        f1 = plot_class_cm(ccl_cm, os.path.join(CCLDIR, "models", model_type,
            dataset, tl  + "_CCL_cm_barplot.png"))
        plt.close("all")
        np.savetxt(os.path.join(CCLDIR, 'models', model_type, dataset, tl  + '_F1_test.csv'),
            f1, fmt='%5.2f', delimiter=",", header='ID,Frac,Cnt,Total')
