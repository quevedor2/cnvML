#############################
# MultiClass Classification #
#############################
# PURPOSE:

#################
# Visualization #
#################
def plot_loss_accuracy(hist, outfile):
    acc = hist.history['accuracy']
    val_acc = hist.history['val_accuracy']
    loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    
    fig, (ax1, ax2) = plt.subplots(2, sharex=True)
    ax1.plot(acc, label='Training Accuracy')
    ax1.plot(val_acc, label='Validation Accuracy')
    ax1.legend(loc='lower right')
    ax1.set_ylabel('Accuracy')
    ax1.set_ylim(0, 1.0) #([min(plt.ylim()),1])
    
    ax2.plot(loss, label='Training Loss')
    ax2.plot(val_loss, label='Validation Loss')
    ax2.legend(loc='upper right')
    ax2.set_ylabel('Cross Entropy')
    ax2.set_xlabel('epoch')
    fig.show()
    fig.savefig(outfile)

def plot_confusion_matrix(model, X, y, range_y, outfile):
    y_pred = list(model.predict_classes(X, verbose=0))
    y = list(y)
    plt.figure(figsize=(8, 6))
    
    # Ensure that all the classes are represented
    y.extend(list(range_y))
    y_pred.extend(list(range_y))
    cm=confusion_matrix(y, y_pred)
    np.fill_diagonal(cm, list(cm.diagonal()-1))
    
    # Make the heatmaps!!!
    sns.heatmap(pd.DataFrame(cm), annot=True, fmt='d', cmap='YlGnBu', alpha=0.8, vmin=0)
    plt.savefig(outfile)
    return cm

def plot_class_cm(cm, outfile,metric ='f1'):
    (p, r, f1) = get_F1score(cm)
    if (metric is 'f1'):
        class_frac=f1
    elif (metric is 'p'):
        class_frac = p
    else:
        class_frac = r
    
    class_frac=class_frac.round(2)
    class_id=list(range(0, len(class_frac)))
    class_df = pd.DataFrame({'ID':class_id, 'Frac':class_frac,
                            'Cnt':cm.diagonal(), 'Total':cm.sum(0)})
    
    #b1=plt.bar("ID", "Total", data=class_df,class_id, class_frac)
    b2=plt.bar("ID", "Frac", data=class_df)
    plt.ylim((0,1))
    #plt.rcParams["figure.figsize"] = [6,2]
    plt.xlabel("Cancer_Types")
    plt.ylabel(metric)
    plt.subplots_adjust(bottom=0.2, top=0.8)
    plt.xticks(class_id, rotation=90)
    plt.savefig(outfile)

def get_F1score(cm):
    precision = cm.diagonal() / cm.sum(axis=0)
    recall = cm.diagonal() / cm.sum(axis=1)
    f1 = 2 * ((precision * recall)/(precision + recall))
    return (precision, recall, f1)

#############################
# MultiClass Classification #
#############################
class MulticlassModels:
    def __init__(self, X, y, model=0):
        self.X = X
        self.y = y
        self.model=model
    
    def sr_model(self):
        print("Softmax-regression model")
        sr_model = Sequential()
        sr_model.add(Dense(y.shape[1], input_shape=(X.shape[1],), activation='softmax'))
        
        sr_model.compile(Adam(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])
        self.model=sr_model
    
    def ann_model(self):
        print("ANN model")
        deep_model = Sequential()
        deep_model.add(Dense(7310*3, input_shape=(X.shape[1],), activation='relu'))
        deep_model.add(Dense(7310, input_shape=(X.shape[1],), activation='relu'))
        deep_model.add(Dense(y.shape[1], activation='softmax'))
        
        deep_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])
        self.model=deep_model


###########
# Modules #
###########
import pandas as pd
import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import sys
import seaborn as sns

from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold
from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

######################################
# Data Visualization & Preprocessing #
######################################
CATEGORIES = ["ACC", "BLCA", "BRCA", "CESC", "CHOL", "COAD",
			  "DLBC", "ESCA", "GBM", "HNSC", "KICH", "KIRC",
			  "KIRP", "LAML", "LGG", "LIHC", "LUAD", "LUSC",
			  "MESO", "OV", "PAAD", "PCPG", "PRAD", "READ",
			  "SARC", "SKCM", "STAD", "TGCT", "THCA", "THYM",
			  "UCEC", "UCS", "UVM", "Normal"]
              
ref_analysis='TCGA_genes'
ccl_analysis='CCL_genes'
pdir='/cluster/projects/pughlab/projects/cancer_cell_lines/'
datadir=Path(os.path.join(pdir, ref_analysis))
os.chdir(datadir)
df = pd.read_csv(datadir / 'data' / 'Modal_Total_CN_matrix.csv')
df = df.drop([df.columns[0]], axis=1)
model_type=sys.argv[1] # 'ann' or 'lr'

## Feature scaling and organizing X and y
X = df.values[:, :-1]
X = X.astype("float")
X[np.isnan(X)] = 2
#ss = StandardScaler()
#X2 = ss.fit_transform(X)
y = pd.get_dummies(df['cancer_type']).values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)

## setup and fit a multi-class logistic regression model
if not os.path.exists(os.path.join(datadir, 'models', model_type, 'model.h5')):
    M = MulticlassModels(X, y)
    if model_type == 'lr':
        M.sr_model()
    elif model_type == 'ann':
        M.ann_model()
    else:
        print("no model selected")
    
    hist = M.model.fit(X_train, y_train, epochs=25,
        verbose=1, validation_split=0.2)
    M.model.save(os.path.join(datadir, 'models', model_type, 'model.h5'))
    M = M.model
else:
    print("Loading existing model...")
    M = load_model(os.path.join(datadir, 'models', model_type, 'model.h5'))

#y_pred_class = M.model.predict_classes(X_test, verbose=0)
#y_test_class = np.argmax(y_test, axis=1)
#print(classification_report(y_test_class, y_pred_class))
#plot_confusion_matrix(M.model, X_test, y_test_class)

###################
# Extract Weights #
###################
W = np.asmatrix(M.get_weights()[0])
np.savetxt(os.path.join(datadir, 'models', model_type, 'weights.csv'),
    W, fmt='%5.2f', delimiter=",")
    
W_ord = W.argsort(axis=0)
np.savetxt(os.path.join(datadir, 'models', model_type, 'weights_ord.csv'),
    W_ord.astype(int), fmt='%i', delimiter=",")

####################
# Spot-check model #
####################
## Training performance
hist = M.history
plot_loss_accuracy(hist, os.path.join(datadir, 'models', model_type, "performance.png"))
plt.close("all")
acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']

loss = hist.history['loss']
val_loss = hist.history['val_loss']

## Test performance
print("Plotting confusion matrix...")
cm = plot_confusion_matrix(M, X_test, np.argmax(y_test, axis=1), range(0, len(CATEGORIES)),
                           os.path.join(datadir, "models",
                           model_type, "lr_confusion-matrix.png"))
plt.close("all")

plot_class_cm(cm, os.path.join(datadir, "models",
            model_type, "cnn_cm_barplot.png"))
plt.close("all")


#####################################
# Expand model to cancer cell lines #
#####################################
## Read in CCL data
ccldir=Path(os.path.join(pdir, ccl_analysis))

ccl_df = pd.read_csv(ccldir / 'data' / 'Modal_Total_CN_matrix.csv')
ccl_df = ccl_df.drop([ccl_df.columns[0]], axis=1)

## Feature scaling and organizing X and y
ccl_X = ccl_df.values[:, :-1].astype("float")
ccl_X[np.isnan(ccl_X)] = 2

## Map only cell line Oncocodes that overlap with TCGA
ccl_tcga_ov = ccl_df['cancer_type'].isin(CATEGORIES)
ccl_tcga_ov.value_counts() #False    1522; True     1257

ccl_XT = ccl_X[ccl_tcga_ov,:]
ccl_yT = ccl_df['cancer_type'][ccl_tcga_ov]
    
## Do prediction testing
ccl_yT_class = [CATEGORIES.index(x) for x in ccl_yT]
ccl_yT_pred = M.predict_classes(ccl_XT, verbose=0)

## Test performance on CCL
print("Plotting confusion matrix...")
ccl_cm = plot_confusion_matrix(M, ccl_XT, ccl_yT_class, range(0, len(CATEGORIES)),
                            os.path.join(ccldir, "models",
                            model_type, "CCLlr_confusion-matrix.png"))
plt.close("all")

plot_class_cm(ccl_cm, os.path.join(ccldir, "models",
            model_type, "CCL_cm_barplot.png"))
plt.close("all")
