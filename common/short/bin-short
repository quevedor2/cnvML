#############################
# MultiClass Classification #
#############################
# PURPOSE:
#################
# Preprocessing #
#################
def balanceGrp(df, q=0.5):
    cnts = df.cancer_type.value_counts()
    target_n = int(np.quantile(cnts, q))
    min_n = int(target_n/4)
    
    # Divide by class
    ctypes = df.cancer_type.unique()
    ctypes = ctypes.tolist()
    ctypes = [ x for x in ctypes if str(x) != 'nan' ]
    
    frames = []
    for ctype in ctypes:
        df_ctype = df[df.cancer_type == ctype]
        if df_ctype.shape[0] < min_n:
            print(ctype + " [Remove]: " + str(df_ctype.shape[0])
                + " < " + str(min_n))
            df_ctype = df_ctype.sample(0, replace=True)
        elif df_ctype.shape[0] < target_n:
            print(ctype + " [Upsample]: " + str(df_ctype.shape[0])
                + " < " + str(target_n))
            df_ctype = df_ctype.sample(target_n, replace=True)
        elif df_ctype.shape[0] > target_n:
            print(ctype + " [Downsample]: " + str(df_ctype.shape[0])
                + " > " + str(target_n))
            df_ctype = df_ctype.sample(target_n, replace=False)
        else :
            df_ctype = df_ctype
        frames.append(df_ctype)
    
    df2 = pd.concat(frames)
    return df2

#################
# Visualization #
#################
def plot_loss_accuracy(hist, outfile):
    acc = hist.history['accuracy']
    val_acc = hist.history['val_accuracy']
    loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    
    fig, (ax1, ax2) = plt.subplots(2, sharex=True)
    ax1.plot(acc, label='Training Accuracy')
    ax1.plot(val_acc, label='Validation Accuracy')
    ax1.legend(loc='lower right')
    ax1.set_ylabel('Accuracy')
    ax1.set_ylim(0, 1.0) #([min(plt.ylim()),1])
    
    ax2.plot(loss, label='Training Loss')
    ax2.plot(val_loss, label='Validation Loss')
    ax2.legend(loc='upper right')
    ax2.set_ylabel('Cross Entropy')
    ax2.set_xlabel('epoch')
    fig.show()
    fig.savefig(outfile)

def plot_confusion_matrix(model, X, y, range_y, outfile):
    y_pred = list(model.predict_classes(X, verbose=0))
    y = list(y)
    plt.figure(figsize=(8, 6))
    
    # Ensure that all the classes are represented
    y.extend(list(range_y))
    y_pred.extend(list(range_y))
    cm=confusion_matrix(y, y_pred)
    np.fill_diagonal(cm, list(cm.diagonal()-1))
    
    # Make the heatmaps!!!
    sns.heatmap(pd.DataFrame(cm), annot=True, fmt='d', cmap='YlGnBu', alpha=0.8, vmin=0)
    plt.savefig(outfile)
    return cm

def plot_class_cm(cm, outfile,metric ='f1'):
    (p, r, f1) = get_F1score(cm)
    if (metric is 'f1'):
        class_frac=f1
    elif (metric is 'p'):
        class_frac = p
    else:
        class_frac = r
    
    class_frac=class_frac.round(2)
    class_id=list(range(0, len(class_frac)))
    class_df = pd.DataFrame({'ID':class_id, 'Frac':class_frac,
                            'Cnt':cm.diagonal(), 'Total':cm.sum(0)})
    
    #b1=plt.bar("ID", "Total", data=class_df,class_id, class_frac)
    b2=plt.bar("ID", "Frac", data=class_df)
    plt.ylim((0,1))
    #plt.rcParams["figure.figsize"] = [6,2]
    plt.xlabel("Cancer_Types")
    plt.ylabel(metric)
    plt.subplots_adjust(bottom=0.2, top=0.8)
    plt.xticks(class_id, rotation=90)
    plt.savefig(outfile)
    
    return class_df

def get_F1score(cm):
    precision = cm.diagonal() / cm.sum(axis=0)
    recall = cm.diagonal() / cm.sum(axis=1)
    f1 = 2 * ((precision * recall)/(precision + recall))
    return (precision, recall, f1)

def get_AACs(PsetDIR):
	aacs = dict()
	for data_type in [ 'CTRPv2', 'gCSI', 'GDSC2' ]:
		aac = pd.read_csv(os.path.join(PsetDIR, data_type + "_aac.csv"))
		aac = aac.rename(index=aac.iloc[:,0])
		aac = aac.drop(aac.columns[0], axis=1)
		aacs[data_type] = aac
	return(aacs)

def getPharmacoIDs(PsetDIR, dataset, Xid, reverse=False):
	meta = pd.read_csv(os.path.join(PsetDIR, "meta_df.csv"))
	if(reverse):
		meta = meta.rename(index=meta['PharmacoGX_ID'])
		search_id=dataset
	else:
		meta = meta.rename(index=meta[dataset])
		search_id='PharmacoGX_ID'
	
	
	pharmacoID=[]
	for cell_line in Xid:
		#import re
		#metavals = [str(i) for i in list(meta.index)]
		#r = re.compile(re.sub("_[^_]*_[^_]*$", "", cell_line))
		#list(filter(r.match, metavals))
		if (meta.index == cell_line).any():
			ret_id = meta.loc[cell_line][search_id]
			if isinstance(ret_id, pd.Series):
				if isinstance(ret_id[[0]][0], str):
					pharmacoID.append(ret_id[[0]][0])
				else:
					pharmacoID.append(ret_id[[1]][0])
			else:
				pharmacoID.append(ret_id)
		else:
			print("Error on sample " + str(cell_line))
			pharmacoID.append(np.nan)
	
	return(pharmacoID)

#############################
# MultiClass Classification #
#############################
class MulticlassModels:
    def __init__(self, X=0, y=0, model=0, fine_tune_at=0,
                 lr=0.0001, y_class='multi'):
        self.X = X
        self.y = y
        self.model=model
        self.fine_tune_at=fine_tune_at
        self.lr=lr
        self.y_class=y_class
    
    def sr_model(self):
        print("Softmax-regression model")
        sr_model = Sequential()
        sr_model.add(Dense(y.shape[1], input_shape=(X.shape[1],), activation='softmax'))
        
        #sr_model.compile(Adam(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])
        sr_model.compile(loss='categorical_crossentropy',
                           optimizer='adam',
                           metrics=['accuracy'])
        self.model=sr_model
    
    def ann_model(self):
        print("ANN model")
        #hidden_n=(X.shape[1] - y.shape[1])/20
        transfer_n = 512
        hidden_n = (transfer_n * 1)
        
        deep_model = Sequential()
        deep_model.add(Dense(int(hidden_n), input_shape=(X.shape[1],), activation='relu', name='start'))
        deep_model.add(Dropout(rate=0.20))
        deep_model.add(Dense(transfer_n, activation='relu', name='transfer_1'))
        
        
        if self.y_class == 'multi':
            deep_model.add(Dense(self.y.shape[1], activation='softmax'))
            deep_model.compile(loss='categorical_crossentropy',
                          optimizer=Adam(learning_rate=self.lr),
                          metrics=['accuracy'])
        elif self.y_class == 'binary':
            deep_model.add(Dense(units=1, activation='sigmoid', name='out'))
            deep_model.compile(loss='binary_crossentropy',
                          optimizer=Adam(learning_rate=self.lr),
                          metrics=['accuracy'])
        elif self.y_class == 'regression':
            deep_model.add(Dense(units=1, name='out'))
            deep_model.compile(loss='mean_squared_error',
                          optimizer=Adam(learning_rate=self.lr))
        else:
            print("y_class must be either 'regression' or 'multi' or 'binary'")
        
        self.model=deep_model
    
    def transfer(self):
        
        regression_model = Sequential()
        for layer in self.model.layers[:-1]: # just exclude last layer from copying
            regression_model.add(layer)
        
        if self.y_class == 'regression':
            regression_model.add(Dense(units=1, name='out'))
        elif self.y_class == 'multi':
            regression_model.add(Dense(self.y.shape[1], activation='softmax', name='out'))
        elif self.y_class == 'binary':
            regression_model.add(Dense(units=1, activation='sigmoid', name='out'))
        self.model = regression_model
        
        print("Transfer learning at layer " + str(self.fine_tune_at))
        # Freeze all layers
        self.model.trainable = True
        
        # Make top layers trainable
        for layer in self.model.layers[:self.fine_tune_at]:
          layer.trainable =  False
        
        if self.y_class == 'multi':
            #model.add(Dense(units=self.y.max()+1, activation='softmax', name='out'))
            self.model.compile(loss='categorical_crossentropy',
                          optimizer=Adam(learning_rate=self.lr),
                          metrics=['accuracy'])
        elif self.y_class == 'binary':
            self.model.compile(loss='binary_crossentropy',
                          optimizer=Adam(learning_rate=self.lr),
                          metrics=['accuracy'])
        elif self.y_class == 'regression':
            self.model.compile(loss='mean_squared_error',
                          optimizer=Adam(learning_rate=self.lr))
        else:
            print("y_class must be either 'regression' or 'classification'")


###########
# Modules #
###########
import pandas as pd
import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import sys
import seaborn as sns

from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold
from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation
from tensorflow.keras.optimizers import Adam
import tensorflow as tf



######################################
# Data Visualization & Preprocessing #
######################################
CATEGORIES = ["ACC", "BLCA", "BRCA", "CESC", "CHOL", "COAD",
			  "DLBC", "ESCA", "GBM", "HNSC", "KICH", "KIRC",
			  "KIRP", "LAML", "LGG", "LIHC", "LUAD", "LUSC",
			  "MESO", "OV", "PAAD", "PCPG", "PRAD", "READ",
			  "SARC", "SKCM", "STAD", "TGCT", "THCA", "THYM",
			  "UCEC", "UCS", "UVM", "Normal"]

ref_analysis='TCGA_bin' #'TCGA_genes', 'TCGA_bin'
ccl_analysis='CCL_bin'
pdir='/cluster/projects/pughlab/projects/cancer_cell_lines/'
datadir=Path(os.path.join(pdir, ref_analysis))
os.chdir(datadir)
df = pd.read_csv(datadir / 'data' / 'Modal_Total_CN_matrix.csv')
df = df.drop([df.columns[0]], axis=1)
df = balanceGrp(df, q=0.5)

## Feature scaling and organizing X and y
X = df.values[:, :-1].astype("float")
X[np.isnan(X)] = 2
ss = StandardScaler() ## purpose: zero mean & unit STDERR
X = ss.fit_transform(X) ## Calculate parameters (mu, std) and transforms

#############
# Variables #
#############

model_type=sys.argv[1]
lr=sys.argv[2]
drug=sys.argv[3]


###################################
# Transfer me some of those drugs #
###################################
PsetDIR='/cluster/projects/pughlab/projects/cancer_cell_lines/PSets'
aacs = get_AACs(PsetDIR)
pharmaco_dict={'CCLE':"CTRPv2", "GDSC":"GDSC2", "GNE":"gCSI"}

## Read in CCL data
CCLDIR=Path(os.path.join(pdir, ccl_analysis))
CCL_DATADIR=os.path.join(CCLDIR, "data")
CCL_OUTDIR=os.path.join(CCLDIR, "models")

dataset = 'CCLE'
ccl_df = pd.read_csv(os.path.join(CCL_DATADIR, dataset, 'Modal_Total_CN_matrix.csv'))
ccl_Xid = ccl_df.index #ccl_df[ccl_df.columns[0]]
ccl_df = ccl_df.drop([ccl_df.columns[0]], axis=1)

## Feature scaling and organizing X and y
ccl_X = ccl_df.values[:, :-1].astype("float")
ccl_X[np.isnan(ccl_X)] = 2

ccl_Xids = getPharmacoIDs(PsetDIR, dataset, ccl_Xid.tolist())
intersect_Xids = aacs[pharmaco_dict[dataset]].columns.intersection(ccl_Xids)
y_aacs = aacs[pharmaco_dict[dataset]][intersect_Xids]

# Subset to cell lines with pharmaco data and Format
dataset_Xids = getPharmacoIDs(PsetDIR, dataset, y_aacs.columns.tolist(), reverse=True)
dataset_idx =[]
for num,id in enumerate(dataset_Xids):
    dataset_idx.append(ccl_Xid.tolist().index(id))

ccl_XT = ccl_X[dataset_idx,:]
ccl_XT = ss.transform(ccl_XT) ## Calculate parameters (mu, std) and transforms

ccl_y = y_aacs.to_numpy()

drugs = ["Bortezomib", "Crizotinib", "Docetaxel", "Entinostat", "Erlotinib",
        "Gemcitabine", "Lapatinib", "Paclitaxel", "Pictilisib", "Sirolimus",
        "Vorinostat"]

########################
# Test drug prediction #
########################
print(drug + "...")
drug_idx = np.where(y_aacs.index == drug)[0][0] # 295 -  Lapatinib

print("Drug: " + y_aacs.index[drug_idx])
ccl_y_drugJ = ccl_y[np.newaxis, drug_idx,:].transpose()
nan_idx = np.where(np.isnan(ccl_y_drugJ))[0].tolist()
ccl_XT_drugJ = np.delete(ccl_XT, nan_idx, axis=0)
ccl_y_drugJ = np.delete(ccl_y_drugJ, nan_idx, axis=0)
ccl_y_drugJ = ccl_y_drugJ.round(4)

max_class=10
ccl_y_drugJ = pd.qcut(ccl_y_drugJ[:,0], max_class, labels=range(max_class)).tolist()
ccl_y_drugJ = np.array(ccl_y_drugJ)
ccl_y_drugJ = ccl_y_drugJ.reshape(ccl_y_drugJ.shape[0], -1)
ccl_y_drugJ_one_hot = tf.keras.utils.to_categorical(ccl_y_drugJ, num_classes=max_class)

transfer_model_path = os.path.join(CCLDIR, 'models', model_type, dataset,
                'drugs', drug + '_transfer_multi' + str(max_class) + '.h5')
naive_model_path = os.path.join(CCLDIR, 'models', model_type, dataset,
                'drugs', drug + '_naive_multi' + str(max_class) + '.h5')

if not os.path.exists(transfer_model_path):
    print("Training transfer model...")
    M = load_model(os.path.join(datadir, 'models', model_type, 'model.h5'))
    M = MulticlassModels(model=M, y=ccl_y_drugJ_one_hot, fine_tune_at=2,
                                 lr=0.0001, y_class='multi')
    M.transfer()
    hist_Tccl = M.model.fit(ccl_XT_drugJ, ccl_y_drugJ_one_hot,
                                    batch_size=32, epochs=30, validation_split=0.2)
    M.model.save(transfer_model_path)

if not os.path.exists(naive_model_path):
    print("Training naive model...")
    Mnaive=MulticlassModels(X=ccl_XT_drugJ, y=ccl_y_drugJ_one_hot,
                            lr=0.0001, y_class='multi')
    Mnaive.ann_model()
    hist_Nccl = Mnaive.model.fit(ccl_XT_drugJ, ccl_y_drugJ_one_hot, batch_size=32,
                                epochs=30, validation_split=0.2)
    Mnaive.model.save(naive_model_path)


for tl in ['naive', 'transfer']:
    if tl == 'transfer':
        M = load_model(transfer_model_path)
    elif tl == 'naive':
        M = load_model(naive_model_path)
    else:
        print("Must be 'naive' or 'transfer'")
    
    for dataset_j in ['GDSC', 'GNE']:
        ccl_df_j = pd.read_csv(os.path.join(CCL_DATADIR, dataset_j, 'Modal_Total_CN_matrix.csv'))
        ccl_Xid_j = ccl_df_j.index #ccl_df[ccl_df.columns[0]]
        #ccl_Xid_j = ccl_df_j[ccl_df_j.columns[0]]
        ccl_df_j = ccl_df_j.drop([ccl_df_j.columns[0]], axis=1)
        
        ## Feature scaling and organizing X and y
        ccl_X_j = ccl_df_j.values[:, :-1].astype("float")
        ccl_X_j[np.isnan(ccl_X_j)] = 2
        
        ccl_Xids_j = getPharmacoIDs(PsetDIR, dataset_j, ccl_Xid_j.tolist())
        intersect_Xids = aacs[pharmaco_dict[dataset_j]].columns.intersection(ccl_Xids_j)
        y_aacs_j = aacs[pharmaco_dict[dataset_j]][intersect_Xids]
        
        # Subset to cell lines with pharmaco data and Format
        dataset_Xids_j = getPharmacoIDs(PsetDIR, dataset_j, y_aacs_j.columns.tolist(), reverse=True)
        dataset_idx =[]
        for num,id in enumerate(dataset_Xids_j):
            dataset_idx.append(ccl_Xid_j.tolist().index(id))
        
        ccl_XT_j = ccl_X_j[dataset_idx,:]
        ccl_XT_j = ss.transform(ccl_XT_j) ## Calculate parameters (mu, std) and transforms
        
        ccl_y_j = y_aacs_j.to_numpy()
        drug_idx_j = np.where(y_aacs_j.index == y_aacs.index[drug_idx])[0][0]
        
        print("Drug: " + y_aacs_j.index[drug_idx_j])
        ccl_y_drugJ_j = ccl_y_j[np.newaxis, drug_idx_j,:].transpose()
        nan_idx = np.where(np.isnan(ccl_y_drugJ_j))[0].tolist()
        ccl_XT_drugJ_j = np.delete(ccl_XT_j, nan_idx, axis=0)
        ccl_y_drugJ_j = np.delete(ccl_y_drugJ_j, nan_idx, axis=0)
        dataset_Xids_j_trim = np.delete(dataset_Xids_j, nan_idx, axis=0)
        ccl_y_drugJ_j_raw = ccl_y_drugJ_j.round(4)
        
        ccl_y_drugJ_j = pd.qcut(ccl_y_drugJ_j_raw[:,0], max_class, labels=range(max_class)).tolist()
        ccl_y_drugJ_j = np.array(ccl_y_drugJ_j)
        ccl_y_drugJ_j = ccl_y_drugJ_j.reshape(ccl_y_drugJ_j.shape[0], -1)
        ccl_y_drugJ_j_one_hot = tf.keras.utils.to_categorical(ccl_y_drugJ_j, num_classes=max_class)
        
        y_pred = list(M.predict_classes(ccl_XT_drugJ_j, verbose=0))
        aac_data = pd.DataFrame({'AAC':list(ccl_y_drugJ_j_raw[:,0]),
                                 'Pred':y_pred,
                                 'Actual':list(np.argmax(ccl_y_drugJ_j_one_hot, axis=1))},
                                 index=list(dataset_Xids_j_trim))
        aac_data.to_csv(os.path.join(CCLDIR, "models", model_type, dataset_j, 'drugs',
                                     drug + "_AAC_" + tl + ".csv"), index=True)
        
        cm = plot_confusion_matrix(M, ccl_XT_drugJ_j, np.argmax(ccl_y_drugJ_j_one_hot, axis=1),
                                   range(max_class), os.path.join(CCLDIR, "models",
                                    model_type, dataset_j, 'drugs',  drug + "_confusion-matrix_" + tl + ".png"))
        plt.close("all")
        f1 = plot_class_cm(cm, os.path.join(CCLDIR, "models",
                           model_type, dataset_j, 'drugs', drug + "_barplot_" + tl + ".png"))
        plt.close("all")
